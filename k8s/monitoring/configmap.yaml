apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    rule_files:
      - "/etc/prometheus/rules/*.yml"

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093

    scrape_configs:
    # ========================================================================================================
    #                                           Health Checks Start
    # ========================================================================================================

      # HAProxy Backend API Servers TCP Health Check
      - job_name: 'haproxy-api-primary-health'
        static_configs:
          - targets: ['api.public.suma-honda.id:443']
        metrics_path: /probe
        params:
          module: [tcp_connect]
        scrape_interval: 30s
        scrape_timeout: 10s
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: blackbox-exporter.monitoring.svc.cluster.local:9115


      - job_name: 'haproxy-api-backup-health'
        static_configs:
          - targets: ['api.suma-honda.id:443']
        metrics_path: /probe
        params:
          module: [tcp_connect]
        scrape_interval: 30s
        scrape_timeout: 10s
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: blackbox-exporter.monitoring.svc.cluster.local:9115

      # Suma Office Web (Laravel Frontend)
      - job_name: 'suma-office-health'
        static_configs:
          - targets: ['suma-office-service.suma-office.svc.cluster.local:8000/login']
        metrics_path: /probe
        params:
          module: [http_2xx]
        scrape_interval: 30s
        scrape_timeout: 10s
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: blackbox-exporter.monitoring.svc.cluster.local:9115

      # Suma Ecommerce Admin (Next.js Frontend)
      - job_name: 'suma-ecommerce-admin-health'
        static_configs:
          - targets: ['suma-ecommerce-admin-service.suma-ecommerce-admin.svc.cluster.local:3000/login']
        metrics_path: /probe
        params:
          module: [http_2xx]
        scrape_interval: 30s
        scrape_timeout: 10s
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: blackbox-exporter.monitoring.svc.cluster.local:9115

      # Suma Ecommerce Client (Next.js Frontend)
      - job_name: 'suma-ecommerce-client-health'
        static_configs:
          - targets: ['suma-ecommerce-client-service.suma-ecommerce-client.svc.cluster.local:3000/login']
        metrics_path: /probe
        params:
          module: [http_2xx]
        scrape_interval: 30s
        scrape_timeout: 10s
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: blackbox-exporter.monitoring.svc.cluster.local:9115

      # NGINX HTTP health check via blackbox (direct health endpoint)
      - job_name: 'nginx-health'
        static_configs:
          - targets: ['nginx-service.nginx-system.svc.cluster.local:80/health']
        metrics_path: /probe
        params:
          module: [http_2xx_follow_redirects]
        scrape_interval: 30s
        scrape_timeout: 10s
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: blackbox-exporter.monitoring.svc.cluster.local:9115
        
      # Ingress NGINX health check via blackbox exporter
      - job_name: 'ingress-nginx-health'
        static_configs:
          - targets: ['http://ingress-nginx-controller.ingress-nginx.svc.cluster.local:80/healthz']
        metrics_path: /probe
        params:
          module: [http_2xx]
        scrape_interval: 30s
        scrape_timeout: 10s
        relabel_configs:
          - source_labels: [__address__]
            target_label: __param_target
          - source_labels: [__param_target]
            target_label: instance
          - target_label: __address__
            replacement: blackbox-exporter.monitoring.svc.cluster.local:9115
    # ========================================================================================================
    #                                           Health Checks Finish
    # ========================================================================================================

      # Prometheus itself
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      # Ingress metrics
      - job_name: 'ingress-nginx'
        kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names: ['ingress-nginx']
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_name]
          action: keep
          regex: ingress-nginx-controller-metrics
        - source_labels: [__meta_kubernetes_endpoint_port_name]
          action: keep
          regex: metrics
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_pod_ip]
          target_label: instance
        - source_labels: [__meta_kubernetes_namespace]
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          target_label: kubernetes_service
        - source_labels: [__meta_kubernetes_pod_name]
          target_label: kubernetes_pod
        metrics_path: /metrics
        scrape_interval: 15s

      # HAProxy metrics (from haproxy-exporter)
      - job_name: 'haproxy'
        static_configs:
          - targets: ['haproxy-exporter.monitoring.svc.cluster.local:9101']
        scrape_interval: 15s
        metrics_path: /metrics

      # Kubernetes cluster monitoring
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      # Kubernetes nodes
      - job_name: 'kubernetes-nodes'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)

      # Kubernetes pods
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__

      # cAdvisor for container metrics
      - job_name: 'cadvisor'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor

      # Blackbox exporter
      - job_name: 'blackbox'
        static_configs:
          - targets: ['blackbox-exporter.monitoring.svc.cluster.local:9115']
        scrape_interval: 15s
        metrics_path: /metrics

  alert_rules.yml: |
    groups:
    - name: suma_applications
      rules:
      - alert: ApplicationDown
        expr: up{job=~"suma-.*|nginx"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Application {{ $labels.job }} is down"
          description: "{{ $labels.job }} has been down for more than 1 minute."

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High response time on {{ $labels.job }}"
          description: "95th percentile response time is {{ $value }}s"

      - alert: HighMemoryUsage
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ $labels.pod }}"
          description: "Memory usage is {{ $value }}%"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: monitoring
data:
  datasources.yml: |
    apiVersion: 1
    datasources:
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://prometheus:9090
      isDefault: true
    - name: Loki
      type: loki
      access: proxy
      url: http://loki:3100

  dashboards.yml: |
    apiVersion: 1
    providers:
    - name: 'all-dashboards'
      orgId: 1
      folder: 'Suma Monitoring'
      type: file
      disableDeletion: false
      editable: true
      updateIntervalSeconds: 10
      options:
        path: /var/lib/grafana/dashboards

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: monitoring
data:
  config.yml: |
    auth_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9096

    common:
      instance_addr: 127.0.0.1
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        kvstore:
          store: inmemory

    schema_config:
      configs:
        - from: 2020-10-24
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h

    storage_config:
      boltdb_shipper:
        active_index_directory: /loki/boltdb-shipper-active
        cache_location: /loki/boltdb-shipper-cache
        shared_store: filesystem
      filesystem:
        directory: /loki/chunks

    limits_config:
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      ingestion_rate_mb: 16
      ingestion_burst_size_mb: 32

    chunk_store_config:
      max_look_back_period: 0s

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s

    ruler:
      storage:
        type: local
        local:
          directory: /loki/rules
      rule_path: /loki/rules
      alertmanager_url: http://alertmanager:9093
      ring:
        kvstore:
          store: inmemory
      enable_api: true

    analytics:
      reporting_enabled: false

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: monitoring
data:
  config.yml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0
    positions:
      filename: /tmp/positions.yaml
    clients:
      - url: http://loki:3100/loki/api/v1/push
    scrape_configs:
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape
        action: keep
        regex: true
      - source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels:
        - __address__
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels:
        - __meta_kubernetes_namespace
        action: replace
        target_label: kubernetes_namespace
      - source_labels:
        - __meta_kubernetes_pod_name
        action: replace
        target_label: kubernetes_pod_name

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  config.yml: |
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alertmanager@suma-honda.id'
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'suma-team'
    receivers:
    - name: 'suma-team'
      webhook_configs:
      - url: 'http://localhost:9093/api/v1/alerts'
        send_resolved: true

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: blackbox-config
  namespace: monitoring
data:
  config.yml: |
    modules:
      http_2xx:
        prober: http
        timeout: 5s
        http:
          valid_http_versions: ["HTTP/1.1", "HTTP/2.0"]
          valid_status_codes: []
          method: GET
          follow_redirects: false
          fail_if_ssl: false
          fail_if_not_ssl: false
          preferred_ip_protocol: "ip4"
      http_2xx_follow_redirects:
        prober: http
        timeout: 10s
        http:
          valid_http_versions: ["HTTP/1.1", "HTTP/2.0"]
          valid_status_codes: []
          method: GET
          follow_redirects: true
          fail_if_ssl: false
          fail_if_not_ssl: false
          preferred_ip_protocol: "ip4"
      icmp:
        prober: icmp
        timeout: 5s
        icmp:
          preferred_ip_protocol: "ip4"
      tcp_connect:
        prober: tcp
        timeout: 5s
        tcp:
          preferred_ip_protocol: "ip4"
